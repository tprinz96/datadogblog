---
title: "The Trump Twitter Trove"
author: "Tristan Prinz"
date: "7/18/2017"
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The 2016 U.S. election was marked (and perhaps marred) by partisan conflict, ideological controversy, and exuberant personalitites. Yet the most striking facet of the election was its conclusion - the American people elected Donald J. Trump to serve as the 45th President of the United States.</p>
<p>The social and culutral mechanisms that guided us to this point in history are worthy of an in-depth anlaysis of their own. However, what distinguished this campaign from every other campaign in U.S. history was the role that media (and in particular social media) played. Never before have candidates been able to influence the American voters psyches in such a frank, profound, and direct way. No other candidate was able to harness the power of this tool quite like Mr. Trump.</p>
<p>Intentionally or not, Trump’s Twitter account served as a stream of consciousness that was oddly candid in its approach, yet nonetheless inflammatory (and at times immature) in its message. It appeared that POTUS-45 tweeted (and continues to tweet) what he wantes and when he wants, without the shackles of a P.R. representative holding his hand along the way. Whether this was a politically wise strategy or not, it became clear that this unpolished approach spoke to a certain archetype of American voter.</p>
<p>In this post, I will use data science techniques to dig into this digital stream of conciousness, and hopefully provide some insights into the trends created and reactions evoked.</p>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<p>The first step in forming my analyses was gathering the source material. This required a fair amount of web surfing - fortunately, I managed to locate a rather messy file (of a meager 26,000 rows…) in the desired .csv format, which was uploaded by a fellow github user a couple months ago. The file was disorganized and contained many components that I was not interested in (such as all the tweets that Mr. Trump retweeted). Below is my coding process to gain all of Trump’s tweets dating back to May 2009 in a clean and manageable format.</p>
<pre class="r"><code># Importing the original csv file
  
tweetdata &lt;- read.csv(&quot;/Users/tristanprinz/Desktop/TrumpTweets.csv&quot;)

# Deleting unwanted columns (i.e. unneccessary variables)

tweetdata.clean.1 &lt;- tweetdata[-c(1:5, 7, 9:11, 13:14, 16:22, 24:192 )]

# Removing rows with NA values and removing arbitrary &#39;screen_name&#39; column

tweetdata.clean.2 &lt;- na.omit(tweetdata.clean.1)

tweetdata.clean.2$screen_name &lt;- NULL

# Formatting the data into my desired layout

tweetdata.clean.2$created_at &lt;- as.Date(tweetdata.clean.2$created_at, &quot;%a %b %d %H:%M:%S %z %Y&quot;)

tweetdata.clean.2$created_at &lt;- format(as.Date(tweetdata.clean.2$created_at), &quot;%m/%d/%Y&quot;)

colnames(tweetdata.clean.2) &lt;- c(&quot;tweet&quot;, &quot;favorites&quot;, &quot;date&quot;, &quot;retweets&quot;)

# Adding an indexing column (for sorting ease)

tweetdata.clean.2$index &lt;- 1:nrow(tweetdata.clean.2)

# Final touches

final.data.1 &lt;- tweetdata.clean.2[,c(5, 1, 2, 3, 4)]

# The line directly below cleverly removes retweets from the dataframe

final.data.2 &lt;- final.data.1[apply(final.data.1[3],1,function(z) !any(z==0)),] 

#This line below removes replacement characters caused by encoding differences

final.data.2$tweet &lt;- gsub(&quot;[^[:alnum:]///&#39; ]&quot;, &quot;&quot;, final.data.2$tweet)

final.data.2$tweet &lt;- tolower(final.data.2$tweet)

# Lets&#39;s assign &#39;final.data.2$tweet&#39; to a variable for ease of access

tt &lt;- final.data.2$tweet </code></pre>
<p>Here’s what the data looks like now</p>
<div class="figure">
<img src="/Users/tristanprinz/Desktop/tweets.png" />

</div>
</div>
<div id="the-document-matrix" class="section level2">
<h2>The Document Matrix</h2>
<p>In order to gain some insight into Trump’s word choice, I needed to transform the tweets into raw, unformatted single words. I also needed to collect a comprehensive ‘stopwords’ collection, because I was only interested in the meaningful words. By utilizing the power of the “tm” package and compiling the tweet data into a “document term matrix”, I was able to get the entire dictionary of significant Trump words, which I will call the ‘Trumptionary’. Below are the coding steps I took to get there.</p>
<pre class="r"><code># Preparing a corpus for analysis

library(tm)</code></pre>
<pre><code>## Loading required package: NLP</code></pre>
<pre class="r"><code>dfCorpus &lt;- Corpus(VectorSource(final.data.2$tweet)) 

# Formatting the corpus

dfCorpus &lt;- tm_map(dfCorpus, removeNumbers)

# Importing a custom stopwords list 

sw &lt;- read.csv(&quot;/Users/tristanprinz/Desktop/stopwords.csv&quot;)

stopwords &lt;- c(sw, stopwords(&quot;english&quot;))

# dfCorpus &lt;- tm_map(dfCorpus, removeWords, stopwords)

dfCorpus &lt;- tm_map(dfCorpus, stripWhitespace)

# Create a document term matrix, and setting boundaries to further filter the words into the one&#39;s we care about

dtmr &lt;- DocumentTermMatrix(dfCorpus, control=list(wordLengths=c(4, 12)))

freqr &lt;- colSums(as.matrix(dtmr))

# With FindFreq function, we can return a list of words that occur in a specified number of Trump&#39;s Tweets (in this exampe, all words that occur in at least 250 of the tweets)

findFreqTerms(dtmr,lowfreq=300)</code></pre>
<pre><code>##  [1] &quot;donald&quot;      &quot;night&quot;       &quot;tonight&quot;     &quot;trump&quot;       &quot;watch&quot;      
##  [6] &quot;with&quot;        &quot;apprentice&quot;  &quot;like&quot;        &quot;think&quot;       &quot;will&quot;       
## [11] &quot;http&quot;        &quot;show&quot;        &quot;very&quot;        &quot;never&quot;       &quot;than&quot;       
## [16] &quot;that&quot;        &quot;them&quot;        &quot;always&quot;      &quot;been&quot;        &quot;interview&quot;  
## [21] &quot;keep&quot;        &quot;your&quot;        &quot;when&quot;        &quot;being&quot;       &quot;best&quot;       
## [26] &quot;great&quot;       &quot;know&quot;        &quot;today&quot;       &quot;from&quot;        &quot;have&quot;       
## [31] &quot;business&quot;    &quot;last&quot;        &quot;thanks&quot;      &quot;first&quot;       &quot;there&quot;      
## [36] &quot;about&quot;       &quot;because&quot;     &quot;they&quot;        &quot;world&quot;       &quot;more&quot;       
## [41] &quot;people&quot;      &quot;what&quot;        &quot;make&quot;        &quot;should&quot;      &quot;many&quot;       
## [46] &quot;this&quot;        &quot;just&quot;        &quot;true&quot;        &quot;back&quot;        &quot;even&quot;       
## [51] &quot;need&quot;        &quot;look&quot;        &quot;amazing&quot;     &quot;country&quot;     &quot;vote&quot;       
## [56] &quot;were&quot;        &quot;time&quot;        &quot;over&quot;        &quot;right&quot;       &quot;much&quot;       
## [61] &quot;their&quot;       &quot;only&quot;        &quot;work&quot;        &quot;would&quot;       &quot;going&quot;      
## [66] &quot;want&quot;        &quot;good&quot;        &quot;obama&quot;       &quot;doing&quot;       &quot;china&quot;      
## [71] &quot;america&quot;     &quot;real&quot;        &quot;better&quot;      &quot;really&quot;      &quot;poll&quot;       
## [76] &quot;thank&quot;       &quot;again&quot;       &quot;barackobama&quot; &quot;deal&quot;        &quot;obamacare&quot;  
## [81] &quot;must&quot;        &quot;jobs&quot;        &quot;president&quot;   &quot;needs&quot;       &quot;ever&quot;       
## [86] &quot;please&quot;      &quot;cont&quot;        &quot;nice&quot;        &quot;love&quot;        &quot;foxnews&quot;    
## [91] &quot;said&quot;        &quot;https&quot;       &quot;clinton&quot;     &quot;hillary&quot;</code></pre>
</div>
<div id="preliminary-observations" class="section level2">
<h2>Preliminary Observations</h2>
<p>Running some basic stats, I found that the most common words were “trump”, “america”, “great”, “make”, “donald”. Regardless of your political views, it is amusing that two of the five most frequent words Trump tweeted to the public were part of his own name… Creating a wordcloud will gives a great visual insight into Trumps vocabulary</p>
<pre class="r"><code>#Create a wordcloud

library(wordcloud)</code></pre>
<pre><code>## Loading required package: RColorBrewer</code></pre>
<pre class="r"><code>set.seed(42)

wordcloud(names(freqr),freqr, min.freq=200, colors=brewer.pal(6, &quot;Dark2&quot;))</code></pre>
<p><img src="/post/trumppost_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="in-depth-analysis" class="section level2">
<h2>In-depth Analysis</h2>
<p>With the data properly scraped, imported, cleaned, and the words filtered and arranged in a document term matrix, the final step is to see which words garner the most reaction and acclaim from the public. This part of my post is still a work in progress, so check in over the next few days to read about my findings.</p>
</div>
